{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6dde269-c552-49c2-9574-d323f39fce56",
   "metadata": {},
   "source": [
    "Question 1: Explain the basic components of a digital image and how it is represented in a computer. State the differences between grayscale and color images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c31e4cb-f4c8-435e-816f-2cb48556da14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d387d87-48a8-42f7-978e-eb5d460ac158",
   "metadata": {},
   "source": [
    "A digital image consists of pixels, which are the smallest units of an image. Each pixel has intensity values representing brightness and color. In computers, images are represented as matrices of pixel values.\n",
    "\n",
    "Grayscale Image:\n",
    "Each pixel has a single intensity value (0 to 255 for an 8-bit image).\n",
    "It is represented as a 2D NumPy array.\n",
    "Color Image:\n",
    "Uses three channels (Red, Green, and Blue - RGB).\n",
    "Each pixel has three values corresponding to these channels.\n",
    "It is represented as a 3D NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e062793-d550-428d-b032-fa8db72d1614",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1587ae65-9dd5-4355-a10f-6cb331a7b3c3",
   "metadata": {},
   "source": [
    "Question 2: Define Convolutional Neural Networks (CNNs) and discuss their role in image processing. Describe the key advantages of using CNNs over traditional neural networks for image-related tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3785aa40-7e65-4f88-93d4-b7d1f75af373",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b6ae3b-509c-493b-bc89-49a567e2da6f",
   "metadata": {},
   "source": [
    "A Convolutional Neural Network (CNN) is a deep learning architecture designed for image processing and pattern recognition. It consists of convolutional layers, activation functions, pooling layers, and fully connected layers.\n",
    "\n",
    "Advantages of CNNs over traditional neural networks:\n",
    "\n",
    "Automatic Feature Extraction – CNNs learn spatial hierarchies, unlike traditional networks that require handcrafted features.\n",
    "Parameter Sharing – Convolutional layers reuse filters, reducing the number of parameters.\n",
    "Translation Invariance – CNNs detect patterns anywhere in the image, unlike fully connected networks.\n",
    "Better Generalization – CNNs reduce overfitting due to pooling layers and shared weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b4b2b63-64e7-4327-addc-c3229348389f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m576\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">93,322</span> (364.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m93,322\u001b[0m (364.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">93,322</span> (364.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m93,322\u001b[0m (364.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Define a simple CNN model\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')  # Output layer for classification\n",
    "])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e6dcfc-4e21-412b-91a4-68d1dacafea7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea81fffe-267b-4583-9d44-34db30438b92",
   "metadata": {},
   "source": [
    "Question 3: Define convolutional layers and their purpose in a CNN. Discuss the concept of filters and how they are applied during the convolution operation. Explain the use of padding and strides in convolutional layers and their impact on the output size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "093598d5-4111-40aa-8a75-349393427ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26c6ae9-eadd-4f2e-9f46-093a0b77762b",
   "metadata": {},
   "source": [
    "Convolutional Layers: These layers apply a set of filters (also called kernels) to the input image to extract features like edges, textures, and shapes.\n",
    "Filters: Small matrices that slide over the input image, performing element-wise multiplication and summation to produce feature maps.\n",
    "Padding:\n",
    "Same Padding: Keeps the output size the same as input by adding extra pixels around the image.\n",
    "Valid Padding: No padding, causing the output size to shrink.\n",
    "Strides: The number of pixels by which the filter moves over the image. Higher stride reduces output size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fb3e27b-a22e-4cc0-ab96-2d7bbd6d7c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 1, 5, 5])\n",
      "Output shape: torch.Size([1, 1, 5, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:64] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define a convolutional layer (1 input channel, 1 output channel, 3x3 kernel, stride 1, padding 1)\n",
    "conv_layer = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "# Create a sample 5x5 grayscale image as a 2D tensor\n",
    "input_image = torch.tensor([[1, 2, 3, 0, 1], \n",
    "                            [5, 6, 7, 1, 0], \n",
    "                            [9, 10, 11, 2, 3], \n",
    "                            [0, 2, 4, 8, 6], \n",
    "                            [5, 6, 7, 1, 0]], dtype=torch.float32)\n",
    "\n",
    "# Reshape input to match PyTorch's expected shape: (batch_size=1, channels=1, height=5, width=5)\n",
    "input_image = input_image.unsqueeze(0).unsqueeze(0)  # Shape: (1, 1, 5, 5)\n",
    "\n",
    "# Apply convolution\n",
    "output_image = conv_layer(input_image)\n",
    "\n",
    "# Print shapes\n",
    "print(f\"Input shape: {input_image.shape}\")   # Should be (1, 1, 5, 5)\n",
    "print(f\"Output shape: {output_image.shape}\") # Should be (1, 1, 5, 5) with padding=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f11e9fb-2057-4982-a82e-6de198e47e00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35df6caa-f43e-4850-abb0-146c6f12a1fd",
   "metadata": {},
   "source": [
    "Question 4: Describe the purpose of pooling layers in CNNs. Compare max pooling and average pooling operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4952cf0-8db8-4470-ba5d-ef48267b38be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411e8cfe-3973-4d2b-8163-44ae533fa531",
   "metadata": {},
   "source": [
    "Pooling layers reduce the spatial dimensions of feature maps while preserving important features. They make the model:\n",
    "\n",
    "More computationally efficient.\n",
    "Less sensitive to small translations.\n",
    "Better at extracting dominant features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e246f69-d512-4880-ad9e-5de8ab5ea126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Pooled Output:\n",
      " tensor([[ 6.,  5.],\n",
      "        [10.,  7.]])\n",
      "Average Pooled Output:\n",
      " tensor([[3.5000, 2.5000],\n",
      "        [6.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define Max Pooling and Average Pooling layers\n",
    "max_pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "avg_pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "# Create a sample 4x4 feature map as a 2D tensor\n",
    "feature_map = torch.tensor([[1, 3, 2, 1], \n",
    "                            [4, 6, 5, 2], \n",
    "                            [8, 10, 7, 4], \n",
    "                            [3, 5, 6, 1]], dtype=torch.float32)\n",
    "\n",
    "# Reshape input to match PyTorch's 4D requirement: (batch_size=1, channels=1, height=4, width=4)\n",
    "feature_map = feature_map.unsqueeze(0).unsqueeze(0)  # Shape: (1, 1, 4, 4)\n",
    "\n",
    "# Apply pooling\n",
    "max_pooled = max_pool(feature_map)\n",
    "avg_pooled = avg_pool(feature_map)\n",
    "\n",
    "# Print results\n",
    "print(\"Max Pooled Output:\\n\", max_pooled.squeeze())  # Remove batch & channel dimensions for readability\n",
    "print(\"Average Pooled Output:\\n\", avg_pooled.squeeze())  # Remove batch & channel dimensions for readability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6447f37f-c288-46ec-9876-05e0832de5a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7045ece8-5a2c-49b9-b235-b30ded2c1d68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d686d050-bc23-4cbe-89f3-1ae9dfa07d7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07308ca8-1234-42fc-9ae1-be649359349c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
